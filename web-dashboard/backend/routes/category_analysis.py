import logging
import statistics
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
import aiohttp
import asyncio
import openai
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI
openai.api_key = "YOUR_OPENAI_API_KEY_HERE"

router = APIRouter(tags=["category_analysis"])

# === –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö ===

class ChartData(BaseModel):
    dates: List[str]
    values: List[float]

class CategoryAnalysisRequest(BaseModel):
    category_path: str
    date_from: str
    date_to: str
    fbs: int = 0

class ProductDetail(BaseModel):
    id: int
    name: str
    brand: str = None
    seller: str = None
    final_price: float
    sales: int
    revenue: float
    rating: float
    comments: int
    purchase: float
    balance: int
    country: str = None
    gender: str = None
    thumb_middle: str = None
    url: str = None
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    basic_sale: float = None
    promo_sale: float = None
    client_sale: float = None
    client_price: float = None
    start_price: float = None
    final_price_max: float = None
    final_price_min: float = None
    average_if_in_stock: float = None
    category_position: int = None
    sku_first_date: str = None
    firstcommentdate: str = None
    picscount: int = None
    hasvideo: bool = None
    has3d: bool = None

class CategoryInfo(BaseModel):
    name: str
    period: str
    total_products: int
    total_revenue: float
    total_sales: int
    average_price: float
    average_rating: float
    average_purchase: float
    average_turnover_days: float
    # –ù–æ–≤—ã–µ –ø–æ–ª—è
    total_suppliers: int = 0
    total_brands: int = 0
    total_articles: int = 0
    monopoly_index: float = 0.0  # –ò–Ω–¥–µ–∫—Å –º–æ–Ω–æ–ø–æ–ª—å–Ω–æ—Å—Ç–∏ (0-1, –≥–¥–µ 1 = –ø–æ–ª–Ω–∞—è –º–æ–Ω–æ–ø–æ–ª–∏—è)
    avg_daily_suppliers_with_orders: float = 0.0
    brands_with_sales: int = 0
    articles_with_sales: int = 0

class CategoryMetrics(BaseModel):
    revenue_per_product: float
    sales_per_product: float
    products_with_sales_percentage: float
    fbs_percentage: float
    average_comments: float
    top_brands_count: int
    price_range_min: float
    price_range_max: float

class CategoryCharts(BaseModel):
    sales_graph: ChartData
    stocks_graph: ChartData
    price_graph: ChartData
    visibility_graph: ChartData

class CategoryRecommendations(BaseModel):
    insights: List[str]
    opportunities: List[str]
    threats: List[str]
    recommendations: List[str]
    market_trends: List[str]
    competitive_advantages: List[str]

class CategoryAnalysisResponse(BaseModel):
    category_info: CategoryInfo
    top_products: List[ProductDetail]
    all_products: List[ProductDetail]
    category_metrics: CategoryMetrics
    aggregated_charts: CategoryCharts
    ai_recommendations: CategoryRecommendations
    metadata: Dict[str, Any]

# === –§—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö ===

def normalize_category_path(category_path: str) -> List[str]:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø—É—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤"""
    variants = []
    
    # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—É—Ç—å
    original = category_path.strip()
    variants.append(original)
    
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ —Å–ª—ç—à–µ–π
    normalized = original.replace(' / ', '/').replace('/ ', '/').replace(' /', '/')
    if normalized != original:
        variants.append(normalized)
    
    # –ó–∞–º–µ–Ω—è–µ–º —Å–ª—ç—à–∏ –Ω–∞ –ø—Ä–æ–±–µ–ª—ã —Å–æ —Å–ª—ç—à–∞–º–∏ (–µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç)
    if '/' in normalized and ' / ' not in normalized:
        spaced = normalized.replace('/', ' / ')
        if spaced not in variants:
            variants.append(spaced)
    
    # –£–±–∏—Ä–∞–µ–º –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    no_double_spaces = ' '.join(normalized.split())
    if no_double_spaces not in variants:
        variants.append(no_double_spaces)
    
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
    segments = normalized.split('/')
    cleaned_segments = [seg.strip() for seg in segments]
    cleaned_path = '/'.join(cleaned_segments)
    if cleaned_path not in variants:
        variants.append(cleaned_path)
    
    # –ü—Ä–æ–±—É–µ–º —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ–≤–∞
    if cleaned_path:
        first_char_lower = cleaned_path[0].lower() + cleaned_path[1:] if len(cleaned_path) > 1 else cleaned_path.lower()
        if first_char_lower not in variants:
            variants.append(first_char_lower)
    
    # –ü—Ä–æ–±—É–µ–º –≤–∞—Ä–∏–∞–Ω—Ç —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤–æ–π –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ–≤–∞ –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
    title_segments = [seg.capitalize() if seg else seg for seg in cleaned_segments]
    title_path = '/'.join(title_segments)
    if title_path not in variants:
        variants.append(title_path)
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
    seen = set()
    unique_variants = []
    for variant in variants:
        if variant and variant not in seen:
            seen.add(variant)
            unique_variants.append(variant)
    
    return unique_variants

async def fetch_mpstats_category_data(category_path: str, date_from: str, date_to: str, fbs: int) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ MPStats API —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤"""
    
    url = "https://mpstats.io/api/wb/get/category"
    headers = {
        'X-Mpstats-TOKEN': '691224ca5c1122.7009638641fe116d63a053fa882deefbd618dcb3',
        'Content-Type': 'application/json'
    }
    
    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø—É—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    path_variants = normalize_category_path(category_path)
    logger.info(f"üîç Trying category path variants: {path_variants}")
    
    last_error = None
    for path_variant in path_variants:
        params = {
            'd1': date_from,
            'd2': date_to,
            'path': path_variant,
            'fbs': fbs
        }
        
        logger.info(f"üöÄ Trying category path: {path_variant}")
        
        all_products = []
        start_row = 0
        batch_size = 5000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ —Å–æ–≥–ª–∞—Å–Ω–æ API
        total_expected = None
        
        try:
            async with aiohttp.ClientSession() as session:
                # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º GET –∑–∞–ø—Ä–æ—Å (–∫–∞–∫ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ñ–∞–π–ª–µ)
                try:
                    async with session.get(url, headers=headers, params=params, timeout=aiohttp.ClientTimeout(total=30)) as get_response:
                        if get_response.status == 200:
                            get_data = await get_response.json()
                            logger.info(f"üì¶ GET response: {json.dumps(get_data, ensure_ascii=False)[:300]}")
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É GET –æ—Ç–≤–µ—Ç–∞
                            if isinstance(get_data, list):
                                all_products = get_data
                                total_expected = len(all_products)
                                logger.info(f"‚úÖ GET request successful: {len(all_products)} products")
                                if len(all_products) > 0:
                                    return {
                                        'data': all_products,
                                        'total': len(all_products),
                                        'used_path': path_variant
                                    }
                            elif isinstance(get_data, dict):
                                get_products = get_data.get('data', get_data.get('items', []))
                                if get_products:
                                    all_products = get_products
                                    total_expected = len(all_products)
                                    logger.info(f"‚úÖ GET request successful: {len(all_products)} products")
                                    if len(all_products) > 0:
                                        return {
                                            'data': all_products,
                                            'total': len(all_products),
                                            'used_path': path_variant
                                        }
                except Exception as get_err:
                    logger.info(f"‚ÑπÔ∏è GET request failed, trying POST: {str(get_err)}")
                
                # –ï—Å–ª–∏ GET –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º POST —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
                while True:
                    json_data = {
                        'startRow': start_row,
                        'endRow': start_row + batch_size,
                        'filterModel': {},
                        'sortModel': []
                    }
                    
                    async with session.post(url, headers=headers, params=params, json=json_data, timeout=aiohttp.ClientTimeout(total=30)) as response:
                        logger.info(f"üìä MPStats API category response: {response.status} (batch: {start_row}-{start_row + batch_size}, path: {path_variant})")
                        
                        if response.status == 200:
                            data = await response.json()
                            
                            # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                            logger.info(f"üì¶ Full response structure: {json.dumps(data, ensure_ascii=False)[:500] if isinstance(data, dict) else str(data)[:500]}")
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç–≤–µ—Ç–∞
                            if isinstance(data, list):
                                # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç - —ç—Ç–æ –º–∞—Å—Å–∏–≤ –Ω–∞–ø—Ä—è–º—É—é
                                products = data
                                total_expected = len(products)
                                logger.info(f"üì¶ Response is a list with {len(products)} items")
                            elif isinstance(data, dict):
                                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å –ø–æ–ª—è–º–∏ data –∏ total
                                products = data.get('data', [])
                                total_expected = data.get('total', len(products))
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–ª—è
                                if not products and 'items' in data:
                                    products = data.get('items', [])
                                    logger.info(f"üì¶ Using 'items' field instead of 'data'")
                                if total_expected == 0 and 'count' in data:
                                    total_expected = data.get('count', 0)
                                    logger.info(f"üì¶ Using 'count' field instead of 'total'")
                                
                                logger.info(f"üì¶ Response data structure: total={total_expected}, products_count={len(products)}, keys={list(data.keys())}")
                            else:
                                logger.warning(f"‚ö†Ô∏è Unexpected response type: {type(data)}")
                                products = []
                                total_expected = 0
                            
                            if products:
                                all_products.extend(products)
                                logger.info(f"‚úÖ Fetched {len(products)} products (total so far: {len(all_products)}/{total_expected})")
                            
                            # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –≤—Å–µ —Ç–æ–≤–∞—Ä—ã –∏–ª–∏ –Ω–µ—Ç –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö
                            if len(all_products) >= total_expected or len(products) == 0:
                                break
                            
                            start_row += batch_size
                        else:
                            error_text = await response.text()
                            logger.warning(f"‚ö†Ô∏è Error fetching category data: {response.status} - {error_text[:200]}")
                            if len(all_products) > 0:
                                # –ï—Å–ª–∏ —É–∂–µ –ø–æ–ª—É—á–∏–ª–∏ —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Ö
                                logger.warning(f"‚ö†Ô∏è Partial data received: {len(all_products)} products")
                                break
                            raise Exception(f"HTTP {response.status}: {error_text[:200]}")
            
            # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–æ–¥—É–∫—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if len(all_products) > 0:
                logger.info(f"‚úÖ Successfully fetched category data with path '{path_variant}': {len(all_products)} products")
                return {
                    'data': all_products,
                    'total': len(all_products),
                    'used_path': path_variant
                }
            else:
                logger.warning(f"‚ö†Ô∏è No products found for path variant: {path_variant} (total_expected={total_expected})")
                
                # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π endpoint /category/items
                try:
                    items_url = "https://mpstats.io/api/wb/get/category/items"
                    items_params = {
                        'path': path_variant,
                        'd1': date_from,
                        'd2': date_to,
                        'fbs': fbs,
                        'limit': 10000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç
                    }
                    
                    async with aiohttp.ClientSession() as items_session:
                        async with items_session.get(items_url, headers=headers, params=items_params, timeout=aiohttp.ClientTimeout(total=30)) as items_response:
                            if items_response.status == 200:
                                items_data = await items_response.json()
                                logger.info(f"üì¶ Items endpoint response: {json.dumps(items_data, ensure_ascii=False)[:300]}")
                                
                                if isinstance(items_data, list) and len(items_data) > 0:
                                    logger.info(f"‚úÖ Items endpoint successful: {len(items_data)} products")
                                    return {
                                        'data': items_data,
                                        'total': len(items_data),
                                        'used_path': path_variant
                                    }
                                elif isinstance(items_data, dict):
                                    items_list = items_data.get('data', items_data.get('items', []))
                                    if isinstance(items_list, list) and len(items_list) > 0:
                                        logger.info(f"‚úÖ Items endpoint successful: {len(items_list)} products")
                                        return {
                                            'data': items_list,
                                            'total': len(items_list),
                                            'used_path': path_variant
                                        }
                except Exception as items_err:
                    logger.info(f"‚ÑπÔ∏è Items endpoint failed: {str(items_err)}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç –±—ã—Ç—å API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤, –Ω–æ —ç—Ç–æ –≤–∞–ª–∏–¥–Ω—ã–π –æ—Ç–≤–µ—Ç
                if total_expected == 0:
                    last_error = f"API –≤–µ—Ä–Ω—É–ª 0 —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø—É—Ç–∏ '{path_variant}' - –∫–∞—Ç–µ–≥–æ—Ä–∏—è –ø—É—Å—Ç–∞ –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥"
                else:
                    last_error = f"No products found for path '{path_variant}'"
                continue
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to fetch data for path '{path_variant}': {str(e)}")
            last_error = str(e)
            continue
    
    # –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
    logger.error(f"‚ùå All path variants failed. Last error: {last_error}")
    return {
        'data': [],
        'total': 0,
        'error': f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category_path}'. –ü–æ–ø—Ä–æ–±–æ–≤–∞–Ω—ã –≤–∞—Ä–∏–∞–Ω—Ç—ã: {', '.join(path_variants)}. {last_error or '–ö–∞—Ç–µ–≥–æ—Ä–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ–π –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –∏–ª–∏ –ø—É—Ç—å —É–∫–∞–∑–∞–Ω –Ω–µ–≤–µ—Ä–Ω–æ.'}"
    }

def generate_dates_for_period(date_from: str, date_to: str, data_length: int = 30) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–∞—Ç –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞"""
    
    try:
        start_date = datetime.fromisoformat(date_from)
        end_date = datetime.fromisoformat(date_to)
        
        # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–Ω—å—à–µ —á–µ–º –¥–Ω–µ–π –≤ –ø–µ—Ä–∏–æ–¥–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ
        period_days = (end_date - start_date).days + 1
        actual_length = min(data_length, period_days, 30)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 30 –¥–Ω—è–º–∏
        
        dates = []
        for i in range(actual_length):
            current_date = end_date - timedelta(days=actual_length - 1 - i)
            dates.append(current_date.strftime("%Y-%m-%d"))
        
        return dates
    except Exception as e:
        logger.warning(f"Error generating dates: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π
        today = datetime.now()
        return [(today - timedelta(days=i)).strftime("%Y-%m-%d") for i in range(29, -1, -1)]

def process_category_info(category_path: str, date_from: str, date_to: str, products: List[Dict], 
                         additional_data: Dict[str, Any] = None) -> CategoryInfo:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    
    total_products = len(products)
    total_revenue = sum(product.get('revenue', 0) for product in products)
    total_sales = sum(product.get('sales', 0) for product in products)
    
    prices = [product.get('final_price', 0) for product in products if product.get('final_price', 0) > 0]
    average_price = statistics.mean(prices) if prices else 0
    
    ratings = [product.get('rating', 0) for product in products if product.get('rating', 0) > 0]
    average_rating = statistics.mean(ratings) if ratings else 0
    
    purchases = [product.get('purchase', 0) for product in products if product.get('purchase', 0) > 0]
    average_purchase = statistics.mean(purchases) if purchases else 0
    
    turnover_days = [product.get('turnover_days', 0) for product in products if product.get('turnover_days', 0) > 0]
    average_turnover_days = statistics.mean(turnover_days) if turnover_days else 0
    
    # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤
    unique_suppliers = set()
    unique_brands = set()
    unique_articles = set()
    articles_with_sales_set = set()
    brands_with_sales_set = set()
    suppliers_with_sales_set = set()
    
    for product in products:
        supplier_id = product.get('supplier_id')
        if supplier_id:
            unique_suppliers.add(supplier_id)
            if product.get('sales', 0) > 0:
                suppliers_with_sales_set.add(supplier_id)
        
        brand = product.get('brand')
        if brand:
            unique_brands.add(brand)
            if product.get('sales', 0) > 0:
                brands_with_sales_set.add(brand)
        
        article_id = product.get('id')
        if article_id:
            unique_articles.add(article_id)
            if product.get('sales', 0) > 0:
                articles_with_sales_set.add(article_id)
    
    total_suppliers = len(unique_suppliers)
    total_brands = len(unique_brands)
    total_articles = len(unique_articles)
    brands_with_sales = len(brands_with_sales_set)
    articles_with_sales = len(articles_with_sales_set)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –º–æ–Ω–æ–ø–æ–ª—å–Ω–æ—Å—Ç–∏ (–¥–æ–ª—è –≤—ã—Ä—É—á–∫–∏ —Ç–æ–ø-1 –ø—Ä–æ–¥–∞–≤—Ü–∞)
    supplier_revenue = {}
    for product in products:
        supplier_id = product.get('supplier_id')
        if supplier_id:
            supplier_revenue[supplier_id] = supplier_revenue.get(supplier_id, 0) + product.get('revenue', 0)
    
    monopoly_index = 0.0
    if supplier_revenue and total_revenue > 0:
        max_supplier_revenue = max(supplier_revenue.values())
        monopoly_index = round(max_supplier_revenue / total_revenue, 3)
    
    # –°—Ä–µ–¥–Ω–µ—Å—É—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤ —Å –∑–∞–∫–∞–∑–∞–º–∏
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ additional_data –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã, –∏–Ω–∞—á–µ –≤—ã—á–∏—Å–ª—è–µ–º –∏–∑ –ø—Ä–æ–¥—É–∫—Ç–æ–≤
    avg_daily_suppliers_with_orders = 0.0
    if additional_data and 'by_date' in additional_data:
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–Ω—è–º
        daily_suppliers = [day.get('sellers_with_sells', 0) for day in additional_data['by_date'] if isinstance(day, dict)]
        if daily_suppliers:
            avg_daily_suppliers_with_orders = round(statistics.mean(daily_suppliers), 1)
    else:
        # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤ —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏ / –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π
        try:
            start_date = datetime.fromisoformat(date_from)
            end_date = datetime.fromisoformat(date_to)
            days_count = (end_date - start_date).days + 1
            if days_count > 0:
                avg_daily_suppliers_with_orders = round(len(suppliers_with_sales_set) / days_count, 1)
        except:
            avg_daily_suppliers_with_orders = round(len(suppliers_with_sales_set), 1)
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
    if additional_data:
        if 'subcategories' in additional_data and isinstance(additional_data['subcategories'], list) and len(additional_data['subcategories']) > 0:
            # –ë–µ—Ä–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–µ—Ä–≤–æ–π –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (—Ç–µ–∫—É—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è)
            subcat_data = additional_data['subcategories'][0]
            total_suppliers = subcat_data.get('sellers', total_suppliers)
            total_brands = subcat_data.get('brands', total_brands)
            total_articles = subcat_data.get('items', total_articles)
            brands_with_sales = subcat_data.get('brands_with_sells', brands_with_sales)
            articles_with_sales = subcat_data.get('items_with_sells', articles_with_sales)
            if 'sellers_with_sells' in subcat_data:
                sellers_with_sells_count = subcat_data.get('sellers_with_sells', 0)
                try:
                    start_date = datetime.fromisoformat(date_from)
                    end_date = datetime.fromisoformat(date_to)
                    days_count = (end_date - start_date).days + 1
                    if days_count > 0:
                        avg_daily_suppliers_with_orders = round(sellers_with_sells_count / days_count, 1)
                except:
                    avg_daily_suppliers_with_orders = round(sellers_with_sells_count, 1)
        
        if 'items' in additional_data and isinstance(additional_data['items'], list) and len(additional_data['items']) > 0:
            # –ë–µ—Ä–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–¥–º–µ—Ç–∞ (—Ç–µ–∫—É—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è)
            items_data = additional_data['items'][0]
            total_articles = items_data.get('items', total_articles)
            articles_with_sales = items_data.get('items_with_sells', articles_with_sales)
            total_brands = items_data.get('brands', total_brands)
            brands_with_sales = items_data.get('brands_with_sells', brands_with_sales)
            total_suppliers = items_data.get('sellers', total_suppliers)
    
    return CategoryInfo(
        name=category_path,
        period=f"{date_from} - {date_to}",
        total_products=total_products,
        total_revenue=total_revenue,
        total_sales=total_sales,
        average_price=round(average_price, 2),
        average_rating=round(average_rating, 2),
        average_purchase=round(average_purchase, 2),
        average_turnover_days=round(average_turnover_days, 1),
        total_suppliers=total_suppliers,
        total_brands=total_brands,
        total_articles=total_articles,
        monopoly_index=monopoly_index,
        avg_daily_suppliers_with_orders=avg_daily_suppliers_with_orders,
        brands_with_sales=brands_with_sales,
        articles_with_sales=articles_with_sales
    )

def process_top_products(products: List[Dict], limit: int = 10) -> List[ProductDetail]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–ø —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –≤—ã—Ä—É—á–∫–µ"""
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—ã—Ä—É—á–∫–µ
    sorted_products = sorted(products, key=lambda x: x.get('revenue', 0), reverse=True)
    top_products = sorted_products[:limit]
    
    result = []
    for product in top_products:
        result.append(ProductDetail(
            id=product.get('id', 0),
            name=product.get('name', ''),
            brand=product.get('brand'),
            seller=product.get('seller'),
            final_price=product.get('final_price', 0),
            sales=product.get('sales', 0),
            revenue=product.get('revenue', 0),
            rating=product.get('rating', 0),
            comments=product.get('comments', 0),
            purchase=product.get('purchase', 0),
            balance=product.get('balance', 0),
            country=product.get('country'),
            gender=product.get('gender'),
            thumb_middle=product.get('thumb_middle'),
            url=product.get('url'),
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            basic_sale=product.get('basic_sale'),
            promo_sale=product.get('promo_sale'),
            client_sale=product.get('client_sale'),
            client_price=product.get('client_price'),
            start_price=product.get('start_price'),
            final_price_max=product.get('final_price_max'),
            final_price_min=product.get('final_price_min'),
            average_if_in_stock=product.get('average_if_in_stock'),
            category_position=product.get('category_position'),
            sku_first_date=product.get('sku_first_date'),
            firstcommentdate=product.get('firstcommentdate'),
            picscount=product.get('picscount'),
            hasvideo=product.get('hasvideo'),
            has3d=product.get('has3d')
        ))
    
    return result

def process_all_products(products: List[Dict]) -> List[ProductDetail]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã"""
    
    result = []
    for product in products:
        result.append(ProductDetail(
            id=product.get('id', 0),
            name=product.get('name', ''),
            brand=product.get('brand'),
            seller=product.get('seller'),
            final_price=product.get('final_price', 0),
            sales=product.get('sales', 0),
            revenue=product.get('revenue', 0),
            rating=product.get('rating', 0),
            comments=product.get('comments', 0),
            purchase=product.get('purchase', 0),
            balance=product.get('balance', 0),
            country=product.get('country'),
            gender=product.get('gender'),
            thumb_middle=product.get('thumb_middle'),
            url=product.get('url'),
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            basic_sale=product.get('basic_sale'),
            promo_sale=product.get('promo_sale'),
            client_sale=product.get('client_sale'),
            client_price=product.get('client_price'),
            start_price=product.get('start_price'),
            final_price_max=product.get('final_price_max'),
            final_price_min=product.get('final_price_min'),
            average_if_in_stock=product.get('average_if_in_stock'),
            category_position=product.get('category_position'),
            sku_first_date=product.get('sku_first_date'),
            firstcommentdate=product.get('firstcommentdate'),
            picscount=product.get('picscount'),
            hasvideo=product.get('hasvideo'),
            has3d=product.get('has3d')
        ))
    
    return result

def process_category_metrics(products: List[Dict]) -> CategoryMetrics:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    
    total_products = len(products)
    if total_products == 0:
        return CategoryMetrics(
            revenue_per_product=0,
            sales_per_product=0,
            products_with_sales_percentage=0,
            fbs_percentage=0,
            average_comments=0,
            top_brands_count=0,
            price_range_min=0,
            price_range_max=0
        )
    
    total_revenue = sum(product.get('revenue', 0) for product in products)
    total_sales = sum(product.get('sales', 0) for product in products)
    
    products_with_sales = len([p for p in products if p.get('sales', 0) > 0])
    products_with_sales_percentage = (products_with_sales / total_products) * 100
    
    fbs_products = len([p for p in products if p.get('fbs', False)])
    fbs_percentage = (fbs_products / total_products) * 100
    
    total_comments = sum(product.get('comments', 0) for product in products)
    average_comments = total_comments / total_products
    
    brands = set(product.get('brand', '') for product in products if product.get('brand'))
    top_brands_count = len(brands)
    
    prices = [product.get('final_price', 0) for product in products if product.get('final_price', 0) > 0]
    price_range_min = min(prices) if prices else 0
    price_range_max = max(prices) if prices else 0
    
    return CategoryMetrics(
        revenue_per_product=round(total_revenue / total_products, 2),
        sales_per_product=round(total_sales / total_products, 2),
        products_with_sales_percentage=round(products_with_sales_percentage, 1),
        fbs_percentage=round(fbs_percentage, 1),
        average_comments=round(average_comments, 1),
        top_brands_count=top_brands_count,
        price_range_min=price_range_min,
        price_range_max=price_range_max
    )

def process_aggregated_charts(products: List[Dict], date_from: str, date_to: str) -> CategoryCharts:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π"""
    
    if not products:
        empty_dates = generate_dates_for_period(date_from, date_to, 30)
        empty_values = [0.0] * len(empty_dates)
        return CategoryCharts(
            sales_graph=ChartData(dates=empty_dates, values=empty_values),
            stocks_graph=ChartData(dates=empty_dates, values=empty_values),
            price_graph=ChartData(dates=empty_dates, values=empty_values),
            visibility_graph=ChartData(dates=empty_dates, values=empty_values)
        )
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –≥—Ä–∞—Ñ–∏–∫–æ–≤
    max_length = 0
    for product in products:
        for graph_type in ["graph", "stocks_graph", "price_graph", "product_visibility_graph"]:
            graph_data = product.get(graph_type, [])
            if isinstance(graph_data, list):
                max_length = max(max_length, len(graph_data))
    
    # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ
    if max_length == 0:
        dates = generate_dates_for_period(date_from, date_to, 30)
        values = [0.0] * len(dates)
        return CategoryCharts(
            sales_graph=ChartData(dates=dates, values=values),
            stocks_graph=ChartData(dates=dates, values=values),
            price_graph=ChartData(dates=dates, values=values),
            visibility_graph=ChartData(dates=dates, values=values)
        )
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –≥—Ä–∞—Ñ–∏–∫–∞ 30 –¥–Ω—è–º–∏
    max_length = min(max_length, 30)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞—Ç—ã –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    dates = generate_dates_for_period(date_from, date_to, max_length)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã
    aggregated_sales = [0.0] * max_length
    aggregated_stocks = [0.0] * max_length
    aggregated_prices = []
    aggregated_visibility = [0.0] * max_length
    
    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –¥–Ω—è–º
    for i in range(max_length):
        sales_sum = 0.0
        stocks_sum = 0.0
        prices_for_avg = []
        visibility_sum = 0.0
        
        for product in products:
            # –ü—Ä–æ–¥–∞–∂–∏ - —Å—É–º–º–∏—Ä—É–µ–º (graph - —ç—Ç–æ –º–∞—Å—Å–∏–≤)
            sales_graph = product.get("graph", [])
            if isinstance(sales_graph, list) and i < len(sales_graph):
                sales_val = sales_graph[i] or 0
                sales_sum += float(sales_val)
            
            # –û—Å—Ç–∞—Ç–∫–∏ - —Å—É–º–º–∏—Ä—É–µ–º (stocks_graph - —ç—Ç–æ –º–∞—Å—Å–∏–≤)
            stocks_graph = product.get("stocks_graph", [])
            if isinstance(stocks_graph, list) and i < len(stocks_graph):
                stocks_val = stocks_graph[i] or 0
                stocks_sum += float(stocks_val)
            
            # –¶–µ–Ω—ã - –±–µ—Ä–µ–º –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è (price_graph - —ç—Ç–æ –º–∞—Å—Å–∏–≤)
            price_graph = product.get("price_graph", [])
            if isinstance(price_graph, list) and i < len(price_graph):
                price = price_graph[i] or 0
                if price > 0:
                    prices_for_avg.append(float(price))
            
            # –í–∏–¥–∏–º–æ—Å—Ç—å - —Å—É–º–º–∏—Ä—É–µ–º (product_visibility_graph - —ç—Ç–æ –º–∞—Å—Å–∏–≤)
            visibility_graph = product.get("product_visibility_graph", [])
            if isinstance(visibility_graph, list) and i < len(visibility_graph):
                visibility_val = visibility_graph[i] or 0
                visibility_sum += float(visibility_val)
        
        aggregated_sales[i] = sales_sum
        aggregated_stocks[i] = stocks_sum
        aggregated_visibility[i] = visibility_sum
        
        # –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞
        avg_price = statistics.mean(prices_for_avg) if prices_for_avg else 0.0
        aggregated_prices.append(round(avg_price, 2))
    
    return CategoryCharts(
        sales_graph=ChartData(dates=dates, values=aggregated_sales),
        stocks_graph=ChartData(dates=dates, values=aggregated_stocks),
        price_graph=ChartData(dates=dates, values=aggregated_prices),
        visibility_graph=ChartData(dates=dates, values=aggregated_visibility)
    )

async def generate_ai_recommendations(category_info: CategoryInfo, products: List[Dict], category_metrics: CategoryMetrics) -> CategoryRecommendations:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenAI"""
    
    try:
        from openai import OpenAI
        
        client = OpenAI(api_key="YOUR_OPENAI_API_KEY_HERE")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è AI
        context = f"""
–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category_info.name}
–ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞: {category_info.period}
–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤: {category_info.total_products}
–û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞: {category_info.total_revenue:,.0f} ‚ÇΩ
–û–±—â–∏–µ –ø—Ä–æ–¥–∞–∂–∏: {category_info.total_sales:,} —à—Ç.
–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {category_info.average_price:,.0f} ‚ÇΩ
–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥: {category_info.average_rating:.1f}/5
–°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –≤—ã–∫—É–ø–∞: {category_info.average_purchase:.1f}%
–î–Ω–∏ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç–∏: {category_info.average_turnover_days:.1f}

–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
- –í—ã—Ä—É—á–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä: {category_metrics.revenue_per_product:,.0f} ‚ÇΩ
- –ü—Ä–æ–¥–∞–∂ –Ω–∞ —Ç–æ–≤–∞—Ä: {category_metrics.sales_per_product:.1f}
- –¢–æ–≤–∞—Ä–æ–≤ —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏: {category_metrics.products_with_sales_percentage:.1f}%
- FBS —Ç–æ–≤–∞—Ä–æ–≤: {category_metrics.fbs_percentage:.1f}%
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—Ä–µ–Ω–¥–æ–≤: {category_metrics.top_brands_count}
- –î–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω: {category_metrics.price_range_min:,.0f} - {category_metrics.price_range_max:,.0f} ‚ÇΩ

–¢–æ–ø-5 —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –≤—ã—Ä—É—á–∫–µ:
"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–ø —Ç–æ–≤–∞—Ä–∞—Ö
        top_5_products = sorted(products, key=lambda x: x.get('revenue', 0), reverse=True)[:5]
        for i, product in enumerate(top_5_products, 1):
            context += f"\n{i}. {product.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')[:50]}..."
            context += f"\n   –ë—Ä–µ–Ω–¥: {product.get('brand', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}"
            context += f"\n   –í—ã—Ä—É—á–∫–∞: {product.get('revenue', 0):,.0f} ‚ÇΩ"
            context += f"\n   –ü—Ä–æ–¥–∞–∂–∏: {product.get('sales', 0):,} —à—Ç."
            context += f"\n   –†–µ–π—Ç–∏–Ω–≥: {product.get('rating', 0):.1f}/5"

        # –ó–∞–ø—Ä–æ—Å –∫ OpenAI —Å –Ω–æ–≤—ã–º API
        response = await asyncio.to_thread(
            client.chat.completions.create,
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤ –∏ e-commerce –∞–Ω–∞–ª–∏—Ç–∏–∫–µ. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ Wildberries –∏ –¥–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
                },
                {
                    "role": "user",
                    "content": f"{context}\n\n–ù–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å:\n1. –ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã (3-4 –ø—É–Ω–∫—Ç–∞)\n2. –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–æ—Å—Ç–∞ (3-4 –ø—É–Ω–∫—Ç–∞)\n3. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —É–≥—Ä–æ–∑—ã (2-3 –ø—É–Ω–∫—Ç–∞)\n4. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (4-5 –ø—É–Ω–∫—Ç–æ–≤)\n5. –†—ã–Ω–æ—á–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã (2-3 –ø—É–Ω–∫—Ç–∞)\n6. –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ (2-3 –ø—É–Ω–∫—Ç–∞)"
                }
            ],
            max_tokens=1000,
            temperature=0.7
        )
        
        ai_text = response.choices[0].message.content
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç AI –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º
        return parse_ai_recommendations(ai_text)
        
    except Exception as e:
        logger.warning(f"Failed to generate AI recommendations: {e}")
        # Fallback –∫ –±–∞–∑–æ–≤—ã–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º
        return generate_fallback_recommendations(category_info, category_metrics)

def parse_ai_recommendations(ai_text: str) -> CategoryRecommendations:
    """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç AI –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
    
    try:
        sections = {
            "insights": [],
            "opportunities": [],
            "threats": [],
            "recommendations": [],
            "market_trends": [],
            "competitive_advantages": []
        }
        
        current_section = None
        
        for line in ai_text.split('\n'):
            line = line.strip()
            if not line:
                continue
                
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–∫—Ü–∏—é
            line_lower = line.lower()
            if any(word in line_lower for word in ['–∏–Ω—Å–∞–π—Ç', 'insight', '–∫–ª—é—á–µ–≤—ã–µ']):
                current_section = "insights"
            elif any(word in line_lower for word in ['–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç', 'opportunity', '—Ä–æ—Å—Ç']):
                current_section = "opportunities"
            elif any(word in line_lower for word in ['—É–≥—Ä–æ–∑', 'threat', '—Ä–∏—Å–∫']):
                current_section = "threats"
            elif any(word in line_lower for word in ['—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏', 'recommend']):
                current_section = "recommendations"
            elif any(word in line_lower for word in ['—Ç—Ä–µ–Ω–¥', 'trend']):
                current_section = "market_trends"
            elif any(word in line_lower for word in ['–ø—Ä–µ–∏–º—É—â–µ—Å—Ç', 'advantage']):
                current_section = "competitive_advantages"
            elif line.startswith(('‚Ä¢', '-', '*', '1.', '2.', '3.', '4.', '5.')) and current_section:
                # –£–±–∏—Ä–∞–µ–º –º–∞—Ä–∫–µ—Ä—ã —Å–ø–∏—Å–∫–∞
                clean_line = line.lstrip('‚Ä¢-*123456789. ')
                if clean_line:
                    sections[current_section].append(clean_line)
        
        return CategoryRecommendations(**sections)
        
    except Exception as e:
        logger.warning(f"Failed to parse AI recommendations: {e}")
        return CategoryRecommendations(
            insights=["–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ AI"],
            opportunities=[],
            threats=[],
            recommendations=[],
            market_trends=[],
            competitive_advantages=[]
        )

def generate_fallback_recommendations(category_info: CategoryInfo, category_metrics: CategoryMetrics) -> CategoryRecommendations:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è fallback —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ AI"""
    
    insights = []
    opportunities = []
    threats = []
    recommendations = []
    market_trends = []
    competitive_advantages = []
    
    # –ê–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
    if category_info.average_rating >= 4.5:
        insights.append(f"–í—ã—Å–æ–∫–∏–π —Ä–µ–π—Ç–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤ ({category_info.average_rating:.1f}/5) —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –ø—Ä–æ–¥—É–∫—Ü–∏—é –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
    elif category_info.average_rating <= 3.5:
        opportunities.append("–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤—ã–¥–µ–ª–∏—Ç—å—Å—è –∫–∞—á–µ—Å—Ç–≤–æ–º - —Å—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ–≤—ã—Å–æ–∫–∏–π")
    
    if category_info.average_purchase >= 70:
        insights.append(f"–û—Ç–ª–∏—á–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç –≤—ã–∫—É–ø–∞ ({category_info.average_purchase:.1f}%) –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã—Å–æ–∫–∏–π —Å–ø—Ä–æ—Å")
    elif category_info.average_purchase <= 40:
        threats.append("–ù–∏–∑–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –≤—ã–∫—É–ø–∞ –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–∞—á–µ—Å—Ç–≤–æ–º –∏–ª–∏ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º")
    
    if category_metrics.products_with_sales_percentage <= 50:
        opportunities.append("–ú–Ω–æ–≥–∏–µ —Ç–æ–≤–∞—Ä—ã –Ω–µ –ø—Ä–æ–¥–∞—é—Ç—Å—è - –µ—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∑–∞—Ö–≤–∞—Ç–∏—Ç—å –∏—Ö –¥–æ–ª—é —Ä—ã–Ω–∫–∞")
        
    if category_metrics.fbs_percentage <= 30:
        opportunities.append("–ù–∏–∑–∫–∞—è –¥–æ–ª—è FBS —Ç–æ–≤–∞—Ä–æ–≤ - –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ —á–µ—Ä–µ–∑ –±—ã—Å—Ç—Ä—É—é –¥–æ—Å—Ç–∞–≤–∫—É")
    
    if category_info.average_turnover_days <= 10:
        competitive_advantages.append("–ë—ã—Å—Ç—Ä–∞—è –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
    elif category_info.average_turnover_days >= 30:
        threats.append("–ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –∑–∞—Ç–æ–≤–∞—Ä–∏–≤–∞–Ω–∏—é")
    
    # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    recommendations.extend([
        "–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å —Ç–æ–ø —Ç–æ–≤–∞—Ä—ã –∏ –∏—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è",
        "–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–∑—ã–≤—ã –ª–∏–¥–µ—Ä–æ–≤ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π",
        "–û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å —Å–µ–∑–æ–Ω–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è —Å–ø—Ä–æ—Å–∞",
        "–ò–∑—É—á–∏—Ç—å —É—Å–ø–µ—à–Ω—ã–µ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤"
    ])
    
    market_trends.extend([
        "–†–æ—Å—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏ –≤ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –Ω–∏—à–∞—Ö",
        "–í–∞–∂–Ω–æ—Å—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
    ])
    
    return CategoryRecommendations(
        insights=insights,
        opportunities=opportunities,
        threats=threats,
        recommendations=recommendations,
        market_trends=market_trends,
        competitive_advantages=competitive_advantages
    )

@router.post("/category-analysis", response_model=CategoryAnalysisResponse)
async def analyze_category(request: CategoryAnalysisRequest):
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    
    try:
        logger.info(f"üéØ Category analysis request: {request.category_path}")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ MPStats API
        external_data = await fetch_mpstats_category_data(
            request.category_path, 
            request.date_from, 
            request.date_to, 
            request.fbs
        )
        
        products = external_data.get('data', [])
        error_message = external_data.get('error')
        used_path = external_data.get('used_path', request.category_path)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å–ø–µ—à–Ω—ã–π –ø—É—Ç—å –∏–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π
        
        if not products:
            logger.warning(f"‚ö†Ô∏è No products found for category: {request.category_path}")
            detail_message = error_message or f"No products found for category '{request.category_path}' in the specified period."
            raise HTTPException(status_code=404, detail=detail_message)
        
        logger.info(f"üìä Processing {len(products)} products for category analysis (used path: {used_path})")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ MPStats API
        additional_data = {}
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            async with aiohttp.ClientSession() as session:
                headers = {
                    'X-Mpstats-TOKEN': '691224ca5c1122.7009638641fe116d63a053fa882deefbd618dcb3',
                    'Content-Type': 'application/json'
                }
                params = {
                    'd1': request.date_from,
                    'd2': request.date_to,
                    'path': used_path,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å–ø–µ—à–Ω—ã–π –ø—É—Ç—å
                    'fbs': request.fbs
                }
                
                # –ó–∞–ø—Ä–æ—Å—ã –∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞–º
                tasks = []
                endpoints = {
                    'subcategories': 'category/subcategories',
                    'items': 'category/items',
                    'by_date': 'category/by_date'
                }
                
                for key, endpoint in endpoints.items():
                    url = f"https://mpstats.io/api/wb/get/{endpoint}"
                    if key == 'by_date':
                        params_with_group = {**params, 'groupBy': 'day'}
                        task = session.get(url, headers=headers, params=params_with_group)
                    else:
                        task = session.get(url, headers=headers, params=params)
                    tasks.append((key, task))
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å—ã
                for key, task in tasks:
                    try:
                        async with task as response:
                            if response.status == 200:
                                data = await response.json()
                                additional_data[key] = data
                                logger.info(f"‚úÖ Fetched {key} data: {len(data) if isinstance(data, list) else 'object'}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Failed to fetch {key} data: {e}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to fetch additional data: {e}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        category_info = process_category_info(request.category_path, request.date_from, request.date_to, products, additional_data)
        top_products = process_top_products(products, 10)
        all_products = process_all_products(products)
        category_metrics = process_category_metrics(products)
        aggregated_charts = process_aggregated_charts(products, request.date_from, request.date_to)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        ai_recommendations = await generate_ai_recommendations(category_info, products, category_metrics)
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            "processing_info": {
                "data_source": "SAMP Analytics Intelligence",
                "processing_timestamp": datetime.now().isoformat(),
                "total_products_found": len(products),
                "period": f"{request.date_from} to {request.date_to}",
                "fbs_filter": request.fbs
            }
        }
        
        logger.info(f"‚úÖ Category analysis completed successfully for: {request.category_path}")
        
        return CategoryAnalysisResponse(
            category_info=category_info,
            top_products=top_products,
            all_products=all_products,
            category_metrics=category_metrics,
            aggregated_charts=aggregated_charts,
            ai_recommendations=ai_recommendations,
            metadata=metadata
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error in category analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}") 